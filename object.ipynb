{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005830e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in ./.venv/lib/python3.12/site-packages (8.3.116)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./.venv/lib/python3.12/site-packages (from ultralytics) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./.venv/lib/python3.12/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./.venv/lib/python3.12/site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (0.17.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in ./.venv/lib/python3.12/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d40f4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2.0.0,>=1.26.0\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-macosx_10_9_x86_64.whl (20.3 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"numpy<2.0.0,>=1.26.0\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2120615b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Volumes/Macintosh-Data/miniconda-quantum/miniconda3/lib/python3.12/site-packages (24.3.1)\n",
      "Collecting pip\n",
      "  Using cached pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Using cached pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.3.1\n",
      "    Uninstalling pip-24.3.1:\n",
      "      Successfully uninstalled pip-24.3.1\n",
      "Successfully installed pip-25.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5047f066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.116 ðŸš€ Python-3.12.5 torch-2.2.2 CPU (Intel Core(TM) i7-8750H 2.20GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=data_kaggle.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=/Users/Dhruv/runs/detect/train11\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431257  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,425 parameters, 2,590,409 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.3 ms, read: 131.2Â±32.2 MB/s, size: 55.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/Dhruv/mlcasee/train/labels.cache... 5000 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.0 ms, read: 156.9Â±28.8 MB/s, size: 80.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/Dhruv/mlcasee/valid/labels.cache... 500 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /Users/Dhruv/runs/detect/train11/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/Dhruv/runs/detect/train11\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100         0G      1.466       1.95      1.131        166        640:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 208/313 [34:34<17:27,  9.97s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      6\u001b[39m model = YOLO(\u001b[33m\"\u001b[39m\u001b[33myolo11n.pt\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# load a pretrained model (recommended for training)\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# model = YOLO(\"yolo11n.yaml\").load(\"yolo11n.pt\")  # build from YAML and transfer weights\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata_kaggle.yaml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/engine/model.py:790\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    787\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m    789\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.hub_session = \u001b[38;5;28mself\u001b[39m.session  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:210\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    207\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/engine/trainer.py:384\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self, world_size)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;28mself\u001b[39m.amp):\n\u001b[32m    383\u001b[39m     batch = \u001b[38;5;28mself\u001b[39m.preprocess_batch(batch)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m     loss, \u001b[38;5;28mself\u001b[39m.loss_items = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m.loss = loss.sum()\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m RANK != -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py:119\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03mPerform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[32m    107\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    116\u001b[39m \u001b[33;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predict(x, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py:300\u001b[39m, in \u001b[36mBaseModel.loss\u001b[39m\u001b[34m(self, batch, preds)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcriterion\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    298\u001b[39m     \u001b[38;5;28mself\u001b[39m.criterion = \u001b[38;5;28mself\u001b[39m.init_criterion()\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m preds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.criterion(preds, batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py:120\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loss(x, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py:138\u001b[39m, in \u001b[36mBaseModel.predict\u001b[39m\u001b[34m(self, x, profile, visualize, augment, embed)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._predict_augment(x)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py:159\u001b[39m, in \u001b[36mBaseModel._predict_once\u001b[39m\u001b[34m(self, x, profile, visualize, embed)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mself\u001b[39m._profile_one_layer(m, x, dt)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m x = \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[32m    160\u001b[39m y.append(x \u001b[38;5;28;01mif\u001b[39;00m m.i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/nn/modules/block.py:302\u001b[39m, in \u001b[36mC2f.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    300\u001b[39m y = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.cv1(x).chunk(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m    301\u001b[39m y.extend(m(y[-\u001b[32m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.m)\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/nn/modules/conv.py:79\u001b[39m, in \u001b[36mConv.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    Apply convolution, batch normalization and activation to input tensor.\u001b[39;00m\n\u001b[32m     72\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     77\u001b[39m \u001b[33;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.act(\u001b[38;5;28mself\u001b[39m.bn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m'\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    453\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(F.pad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode),\n\u001b[32m    454\u001b[39m                     weight, bias, \u001b[38;5;28mself\u001b[39m.stride,\n\u001b[32m    455\u001b[39m                     _pair(\u001b[32m0\u001b[39m), \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups)\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "# model = YOLO(\"yolo11n.yaml\")  # build a new model from YAML\n",
    "model = YOLO(\"yolo11n.pt\")  # load a pretrained model (recommended for training)\n",
    "# model = YOLO(\"yolo11n.yaml\").load(\"yolo11n.pt\")  # build from YAML and transfer weights\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"data_kaggle.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14dab033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/Dhruv/mlcasee/test/images/bcec9d23-1430d31c_jpg.rf.5d7e5d1107953fd6b674decc945c543a.jpg: 640x640 6 persons, 4 cars, 1 traffic light, 180.0ms\n",
      "Speed: 7.5ms preprocess, 180.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'predicted.jpg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Run inference on an image\n",
    "results = model(\"test/images/bcec9d23-1430d31c_jpg.rf.5d7e5d1107953fd6b674decc945c543a.jpg\")  # replace with your image path\n",
    "\n",
    "# Show the results\n",
    "results[0].show()  # this opens the image with bounding boxes\n",
    "# Or save the results to disk\n",
    "results[0].save(filename=\"predicted.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5530bced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/Dhruv/mlcasee/test/images/bd0a1433-99c735e8_jpg.rf.51969b5ea6b475ea81de9de23dc80e5b.jpg: 640x640 2 persons, 3 cars, 1 bus, 1 traffic light, 153.4ms\n",
      "Speed: 4.0ms preprocess, 153.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'predicted.jpg'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Run inference on an image\n",
    "results = model(\"test/images/bd0a1433-99c735e8_jpg.rf.51969b5ea6b475ea81de9de23dc80e5b.jpg\")  # replace with your image path\n",
    "\n",
    "# Show the results\n",
    "results[0].show()  # this opens the image with bounding boxes\n",
    "# Or save the results to disk\n",
    "results[0].save(filename=\"predicted.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7e655c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/Dhruv/mlcasee/test/images/c5434464-5dcb3bd7_jpg.rf.88c4d9e9d09f7d61d8b60a1c4a09852e.jpg: 640x640 3 persons, 8 cars, 2 traffic lights, 261.3ms\n",
      "Speed: 5.7ms preprocess, 261.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'predicted.jpg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Run inference on an image\n",
    "results = model(\"test/images/c5434464-5dcb3bd7_jpg.rf.88c4d9e9d09f7d61d8b60a1c4a09852e.jpg\")  # replace with your image path\n",
    "\n",
    "# Show the results\n",
    "results[0].show()  # this opens the image with bounding boxes\n",
    "# Or save the results to disk\n",
    "results[0].save(filename=\"predicted.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7add5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m image_path = \u001b[33m\"\u001b[39m\u001b[33mtest/images/c7339013-3979b7a2_jpg.rf.47c00312dcec95f42018c1f07e60b8ca.jpg\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# update this path as needed\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Run inference\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m results = \u001b[43mmodel\u001b[49m(image_path)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Show result\u001b[39;00m\n\u001b[32m      8\u001b[39m results[\u001b[32m0\u001b[39m].show()\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Use a valid image path from your dataset\n",
    "image_path = \"test/images/c7339013-3979b7a2_jpg.rf.47c00312dcec95f42018c1f07e60b8ca.jpg\"  # update this path as needed\n",
    "\n",
    "# Run inference\n",
    "results = model(image_path)\n",
    "\n",
    "# Show result\n",
    "results[0].show()\n",
    "\n",
    "# Save output\n",
    "results[0].save(filename=\"predicted.jpg\")\n",
    "\n",
    "print(\"Prediction saved as predicted.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "502eedb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in 'valid/images': 500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_files_in_folder(folder_path):\n",
    "    try:\n",
    "        files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "        print(f\"Number of files in '{folder_path}': {len(files)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Folder '{folder_path}' not found.\")\n",
    "\n",
    "# Example usage\n",
    "folder_path = 'valid/images'\n",
    "count_files_in_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45bc2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in ./.venv/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./.venv/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2e148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read images\n",
    "image1 = cv2.imread('test/images/c5879538-6312ddd1_jpg.rf.b842158558b20c09d1068bd8a3d21297.jpg')\n",
    "image2 = cv2.imread('test/images/c5882339-42bfd7a8_jpg.rf.43c3e0edb7220d0f5edbcdd22ebb662c.jpg')\n",
    "\n",
    "# Convert to grayscale if needed\n",
    "image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Addition\n",
    "add_result = cv2.add(image1, image2)\n",
    "\n",
    "# Subtraction\n",
    "sub_result = cv2.subtract(image1, image2)\n",
    "\n",
    "# Multiplication\n",
    "mult_result = cv2.multiply(image1, image2)\n",
    "\n",
    "# Division\n",
    "div_result = cv2.divide(image1, image2)\n",
    "\n",
    "# Scalar Addition\n",
    "scalar_result = cv2.add(image1, 50)\n",
    "\n",
    "# Blending\n",
    "blend_result = cv2.addWeighted(image1, 0.7, image2, 0.3, 0)\n",
    "\n",
    "# Display one result\n",
    "cv2.imshow('Addition Result', add_result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f7218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/Dhruv/mlcasee/test/images/c7339013-3979b7a2_jpg.rf.47c00312dcec95f42018c1f07e60b8ca.jpg: 640x640 2 cars, 1 traffic light, 271.4ms\n",
      "Speed: 17.7ms preprocess, 271.4ms inference, 16.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def calculate_focal_length(image_width_pixels, fov_degrees=70):\n",
    "    fov_radians = math.radians(fov_degrees)\n",
    "    focal_length_pixels = (image_width_pixels / 2) / math.tan(fov_radians / 2)\n",
    "    return focal_length_pixels\n",
    "\n",
    "def estimate_distance(real_height_meters, focal_length_pixels, bbox_height_pixels):\n",
    "    distance_meters = (real_height_meters * focal_length_pixels) / bbox_height_pixels\n",
    "    return distance_meters\n",
    "\n",
    "def draw_distance_vector(image, bbox, distance):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    # Center bottom of the bounding box\n",
    "    center_x = int((x1 + x2) / 2)\n",
    "    bottom_y = y2\n",
    "\n",
    "    # Draw arrow from bottom of object to bottom of image\n",
    "    image_height = image.shape[0]\n",
    "    cv2.arrowedLine(image, (center_x, bottom_y), (center_x, image_height - 10), color=(0, 255, 0), thickness=2, tipLength=0.05)\n",
    "\n",
    "    # Put distance text above the bounding box\n",
    "    label = f\"{distance:.2f}m\"\n",
    "    cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "# Use an image for inference\n",
    "image_path = 'test/images/c7339013-3979b7a2_jpg.rf.47c00312dcec95f42018c1f07e60b8ca.jpg'\n",
    "input_image = cv2.imread(image_path)\n",
    "image_height, image_width, _ = input_image.shape\n",
    "\n",
    "# Calculate focal length\n",
    "f_pixels = calculate_focal_length(image_width, fov_degrees=70)\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Run YOLO detection\n",
    "results = model(image_path)\n",
    "result = results[0]\n",
    "\n",
    "# Create a copy of the image to draw on\n",
    "image = input_image.copy()\n",
    "\n",
    "# Process each detection\n",
    "boxes = result.boxes\n",
    "for box in boxes:\n",
    "    # Get box coordinates (x1, y1, x2, y2)\n",
    "    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "    bbox = (x1, y1, x2, y2)\n",
    "    \n",
    "    # Calculate bbox height\n",
    "    bbox_height_pixels = y2 - y1\n",
    "    \n",
    "    # Get the class of the detected object\n",
    "    cls = int(box.cls[0])\n",
    "    class_name = result.names[cls]\n",
    "    \n",
    "    # Define real-world height based on class (adjust as needed)\n",
    "    real_height_meters = 1.5  # Default height\n",
    "    if class_name.lower() == 'person':\n",
    "        real_height_meters = 1.7  # Average human height\n",
    "    \n",
    "    # Calculate distance\n",
    "    distance = estimate_distance(real_height_meters, f_pixels, bbox_height_pixels)\n",
    "    \n",
    "    # Draw distance vector\n",
    "    draw_distance_vector(image, bbox, distance)\n",
    "\n",
    "# Show and save the output image\n",
    "cv2.imshow(\"Distance Estimation\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite('output_with_distances.jpg', image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de688af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in ./.venv/lib/python3.12/site-packages (8.3.116)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.12/site-packages (0.13.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./.venv/lib/python3.12/site-packages (from ultralytics) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./.venv/lib/python3.12/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./.venv/lib/python3.12/site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (0.17.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in ./.venv/lib/python3.12/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading scikit_learn-1.7.1-cp312-cp312-macosx_10_13_x86_64.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.2/9.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 102, in read\n",
      "    self.__buf.write(data)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/tempfile.py\", line 499, in func_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_internal/commands/install.py\", line 386, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py\", line 554, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_internal/operations/prepare.py\", line 469, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_internal/network/download.py\", line 184, in __call__\n",
      "    for chunk in chunks:\n",
      "                 ^^^^^^\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_internal/cli/progress_bars.py\", line 55, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "                 ^^^^^^^^\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_internal/network/utils.py\", line 65, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 455, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: OSError(28, 'No space left on device')\", OSError(28, 'No space left on device'))\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics matplotlib seaborn scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a3f9e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '__check_build' from partially initialized module 'sklearn' (most likely due to a circular import) (/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/sklearn/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, ConfusionMatrixDisplay\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/sklearn/__init__.py:69\u001b[39m\n\u001b[32m     60\u001b[39m os.environ.setdefault(\u001b[33m\"\u001b[39m\u001b[33mKMP_INIT_AT_FORK\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mFALSE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[32m     70\u001b[39m     __check_build,\n\u001b[32m     71\u001b[39m     _distributor_init,\n\u001b[32m     72\u001b[39m )\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name '__check_build' from partially initialized module 'sklearn' (most likely due to a circular import) (/Users/Dhruv/mlcasee/.venv/lib/python3.12/site-packages/sklearn/__init__.py)"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load your trained model\n",
    "model = YOLO('yolo11n.pt')  # Adjust path if needed\n",
    "\n",
    "# Evaluate on validation or test set (assumes same YAML or default split)\n",
    "results = model.val()\n",
    "\n",
    "# -----------------------\n",
    "# 1. mAP and PR Curve Plot\n",
    "# -----------------------\n",
    "def plot_pr_curve(pr_curve_data):\n",
    "    for class_idx, pr in enumerate(pr_curve_data):\n",
    "        plt.plot(pr[:, 0], pr[:, 1], label=f'Class {class_idx}')\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_pr_curve(results.pr_curves)\n",
    "\n",
    "# -----------------------\n",
    "# 2. F1 Score vs Confidence\n",
    "# -----------------------\n",
    "def plot_f1_conf(results):\n",
    "    conf_thresholds = results.f1[:, 0]\n",
    "    f1_scores = results.f1[:, 1]\n",
    "    plt.plot(conf_thresholds, f1_scores)\n",
    "    plt.xlabel(\"Confidence Threshold\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.title(\"F1 Score vs Confidence Threshold\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_f1_conf(results)\n",
    "\n",
    "# -----------------------\n",
    "# 3. Confusion Matrix\n",
    "# -----------------------\n",
    "def plot_conf_matrix(results):\n",
    "    matrix = results.confusion_matrix\n",
    "    if matrix is not None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=results.names)\n",
    "        disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "plot_conf_matrix(results)\n",
    "\n",
    "# -----------------------\n",
    "# 4. Print Metrics\n",
    "# -----------------------\n",
    "print(\"Results Summary:\")\n",
    "for k, v in results.metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf49ef0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.116 ðŸš€ Python-3.12.5 torch-2.2.2 CPU (Intel Core(TM) i7-8750H 2.20GHz)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.2Â±0.2 ms, read: 193.4Â±38.0 MB/s, size: 85.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/Dhruv/mlcasee/valid/labels.cache... 500 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [02:10<00:00,  4.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       8253      0.031      0.334     0.0215    0.00909\n",
      "                person        495       5100     0.0392      0.313     0.0266     0.0109\n",
      "               bicycle        500       2372     0.0422     0.0489     0.0223    0.00814\n",
      "                   car        500        781     0.0116      0.639     0.0157    0.00829\n",
      "Speed: 5.2ms preprocess, 229.6ms inference, 0.0ms loss, 9.0ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/Dhruv/runs/detect/val6\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DetMetrics' object has no attribute 'pr_curves'. See valid attributes below.\n\n    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP).\n\n    Attributes:\n        save_dir (Path): A path to the directory where the output plots will be saved.\n        plot (bool): A flag that indicates whether to plot precision-recall curves for each class.\n        names (dict): A dictionary of class names.\n        box (Metric): An instance of the Metric class for storing detection results.\n        speed (dict): A dictionary for storing execution times of different parts of the detection process.\n        task (str): The task type, set to 'detect'.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m     plt.grid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     30\u001b[39m     plt.show()\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m plot_pr_curve(\u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpr_curves\u001b[49m, results.names)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# 4. F1 Score vs Confidence Threshold\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_f1_vs_conf\u001b[39m(f1_data):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/utils/__init__.py:241\u001b[39m, in \u001b[36mSimpleClass.__getattr__\u001b[39m\u001b[34m(self, attr)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[32m    240\u001b[39m name = \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DetMetrics' object has no attribute 'pr_curves'. See valid attributes below.\n\n    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP).\n\n    Attributes:\n        save_dir (Path): A path to the directory where the output plots will be saved.\n        plot (bool): A flag that indicates whether to plot precision-recall curves for each class.\n        names (dict): A dictionary of class names.\n        box (Metric): An instance of the Metric class for storing detection results.\n        speed (dict): A dictionary for storing execution times of different parts of the detection process.\n        task (str): The task type, set to 'detect'.\n    "
     ]
    }
   ],
   "source": [
    "# %pip install --force-reinstall scikit-learn\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# 1. Load the fine-tuned model\n",
    "# -------------------------\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# -------------------------\n",
    "# 2. Evaluate the model\n",
    "# Replace with your YAML path if needed: data='path/to/data.yaml'\n",
    "results = model.val(data=\"data_kaggle.yaml\")\n",
    "\n",
    "# -------------------------\n",
    "# 3. Precision-Recall Curve\n",
    "# -------------------------\n",
    "def plot_pr_curve(pr_curves, class_names):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i, pr in enumerate(pr_curves):\n",
    "        if pr is not None:\n",
    "            plt.plot(pr[:, 0], pr[:, 1], label=class_names[i])\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_pr_curve(results.pr_curves, results.names)\n",
    "\n",
    "# -------------------------\n",
    "# 4. F1 Score vs Confidence Threshold\n",
    "# -------------------------\n",
    "def plot_f1_vs_conf(f1_data):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    conf_thresholds = f1_data[:, 0]\n",
    "    f1_scores = f1_data[:, 1]\n",
    "    plt.plot(conf_thresholds, f1_scores, color='purple')\n",
    "    plt.xlabel(\"Confidence Threshold\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.title(\"F1 Score vs Confidence\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_f1_vs_conf(results.f1)\n",
    "\n",
    "# -------------------------\n",
    "# 5. Confusion Matrix\n",
    "# -------------------------\n",
    "def plot_confusion_matrix(results):\n",
    "    matrix = results.confusion_matrix\n",
    "    if matrix is not None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=list(results.names.values()))\n",
    "        disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "plot_confusion_matrix(results)\n",
    "\n",
    "# -------------------------\n",
    "# 6. mAP and Summary Metrics\n",
    "# -------------------------\n",
    "print(\"\\nðŸ“Š Model Evaluation Summary:\")\n",
    "for metric, value in results.metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da6b2c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Removing corrupted cache: valid/labels.cache\n",
      "Ultralytics 8.3.116 ðŸš€ Python-3.12.5 torch-2.2.2 CPU (Intel Core(TM) i7-8750H 2.20GHz)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 168.8Â±52.2 MB/s, size: 81.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/Dhruv/mlcasee/valid/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1318.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/Dhruv/mlcasee/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [01:21<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       8253      0.031      0.334     0.0215    0.00909\n",
      "                person        495       5100     0.0392      0.313     0.0266     0.0109\n",
      "               bicycle        500       2372     0.0422     0.0489     0.0223    0.00814\n",
      "                   car        500        781     0.0116      0.639     0.0157    0.00829\n",
      "Speed: 4.1ms preprocess, 143.9ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/Dhruv/runs/detect/val4\u001b[0m\n",
      "\n",
      "ðŸ“‚ Evaluation plots saved at: /Users/Dhruv/runs/detect/val4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# ------------------------\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# ðŸ“¸ Step 4: Plot & save all evaluation graphs\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# ------------------------\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“‚ Evaluation plots saved at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults.save_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This saves: PR curve, confusion matrix, F1 curve, labels\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# ------------------------\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# ðŸ§¾ Step 5: Print metrics\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# ------------------------\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“Š Model Evaluation Summary:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'bool' object is not callable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------\n",
    "# ðŸ’¡ Step 1: Remove corrupted cache if exists\n",
    "# ------------------------\n",
    "CACHE_PATH = \"valid/labels.cache\"  # Update if needed\n",
    "if os.path.exists(CACHE_PATH):\n",
    "    print(f\"ðŸ§¹ Removing corrupted cache: {CACHE_PATH}\")\n",
    "    os.remove(CACHE_PATH)\n",
    "\n",
    "# ------------------------\n",
    "# ðŸš€ Step 2: Load model\n",
    "# ------------------------\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# ------------------------\n",
    "# ðŸ§ª Step 3: Run evaluation\n",
    "# ------------------------\n",
    "results = model.val(data=\"data_kaggle.yaml\")  # Update if needed\n",
    "\n",
    "# ------------------------\n",
    "# ðŸ“¸ Step 4: Plot & save all evaluation graphs\n",
    "# ------------------------\n",
    "print(f\"\\nðŸ“‚ Evaluation plots saved at: {results.save_dir}\")\n",
    "results.plot()  # This saves: PR curve, confusion matrix, F1 curve, labels\n",
    "\n",
    "# ------------------------\n",
    "# ðŸ§¾ Step 5: Print metrics\n",
    "# ------------------------\n",
    "print(\"\\nðŸ“Š Model Evaluation Summary:\")\n",
    "metrics = results.box\n",
    "print(f\"Precision:     {metrics.precision.mean():.4f}\")\n",
    "print(f\"Recall:        {metrics.recall.mean():.4f}\")\n",
    "print(f\"mAP@0.5:       {metrics.map50.mean():.4f}\")\n",
    "print(f\"mAP@0.5:0.95:  {metrics.map.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f0b3205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Removing corrupted cache: valid/labels.cache\n",
      "Ultralytics 8.3.116 ðŸš€ Python-3.12.5 torch-2.2.2 CPU (Intel Core(TM) i7-8750H 2.20GHz)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.1Â±0.0 ms, read: 138.2Â±114.2 MB/s, size: 62.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/Dhruv/mlcasee/valid/labels... 500 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1124.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/Dhruv/mlcasee/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [01:35<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       8253      0.031      0.334     0.0215    0.00909\n",
      "                person        495       5100     0.0392      0.313     0.0266     0.0109\n",
      "               bicycle        500       2372     0.0422     0.0489     0.0223    0.00814\n",
      "                   car        500        781     0.0116      0.639     0.0157    0.00829\n",
      "Speed: 4.5ms preprocess, 166.9ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/Dhruv/runs/detect/val5\u001b[0m\n",
      "\n",
      "ðŸ“‚ Evaluation plots have been auto-saved to: /Users/Dhruv/runs/detect/val5\n",
      "ðŸ–¼ï¸ Plots include: PR curve, F1 curve, confusion matrix, label distribution\n",
      "\n",
      "ðŸ“Š Model Evaluation Summary:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Metric' object has no attribute 'precision'. See valid attributes below.\n\n    Class for computing evaluation metrics for YOLOv8 model.\n\n    Attributes:\n        p (list): Precision for each class. Shape: (nc,).\n        r (list): Recall for each class. Shape: (nc,).\n        f1 (list): F1 score for each class. Shape: (nc,).\n        all_ap (list): AP scores for all classes and all IoU thresholds. Shape: (nc, 10).\n        ap_class_index (list): Index of class for each AP score. Shape: (nc,).\n        nc (int): Number of classes.\n\n    Methods:\n        ap50(): AP at IoU threshold of 0.5 for all classes. Returns: List of AP scores. Shape: (nc,) or [].\n        ap(): AP at IoU thresholds from 0.5 to 0.95 for all classes. Returns: List of AP scores. Shape: (nc,) or [].\n        mp(): Mean precision of all classes. Returns: Float.\n        mr(): Mean recall of all classes. Returns: Float.\n        map50(): Mean AP at IoU threshold of 0.5 for all classes. Returns: Float.\n        map75(): Mean AP at IoU threshold of 0.75 for all classes. Returns: Float.\n        map(): Mean AP at IoU thresholds from 0.5 to 0.95 for all classes. Returns: Float.\n        mean_results(): Mean of results, returns mp, mr, map50, map.\n        class_result(i): Class-aware result, returns p[i], r[i], ap50[i], ap[i].\n        maps(): mAP of each class. Returns: Array of mAP scores, shape: (nc,).\n        fitness(): Model fitness as a weighted combination of metrics. Returns: Float.\n        update(results): Update metric attributes with new evaluation results.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m metrics = results.box\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“Š Model Evaluation Summary:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrecision:     \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmetrics\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprecision\u001b[49m.mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecall:        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics.recall.mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmAP@0.5:       \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics.map50.mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/utils/__init__.py:241\u001b[39m, in \u001b[36mSimpleClass.__getattr__\u001b[39m\u001b[34m(self, attr)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[32m    240\u001b[39m name = \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Metric' object has no attribute 'precision'. See valid attributes below.\n\n    Class for computing evaluation metrics for YOLOv8 model.\n\n    Attributes:\n        p (list): Precision for each class. Shape: (nc,).\n        r (list): Recall for each class. Shape: (nc,).\n        f1 (list): F1 score for each class. Shape: (nc,).\n        all_ap (list): AP scores for all classes and all IoU thresholds. Shape: (nc, 10).\n        ap_class_index (list): Index of class for each AP score. Shape: (nc,).\n        nc (int): Number of classes.\n\n    Methods:\n        ap50(): AP at IoU threshold of 0.5 for all classes. Returns: List of AP scores. Shape: (nc,) or [].\n        ap(): AP at IoU thresholds from 0.5 to 0.95 for all classes. Returns: List of AP scores. Shape: (nc,) or [].\n        mp(): Mean precision of all classes. Returns: Float.\n        mr(): Mean recall of all classes. Returns: Float.\n        map50(): Mean AP at IoU threshold of 0.5 for all classes. Returns: Float.\n        map75(): Mean AP at IoU threshold of 0.75 for all classes. Returns: Float.\n        map(): Mean AP at IoU thresholds from 0.5 to 0.95 for all classes. Returns: Float.\n        mean_results(): Mean of results, returns mp, mr, map50, map.\n        class_result(i): Class-aware result, returns p[i], r[i], ap50[i], ap[i].\n        maps(): mAP of each class. Returns: Array of mAP scores, shape: (nc,).\n        fitness(): Model fitness as a weighted combination of metrics. Returns: Float.\n        update(results): Update metric attributes with new evaluation results.\n    "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ------------------------\n",
    "# ðŸ’¡ Step 1: Remove corrupted cache if exists\n",
    "# ------------------------\n",
    "CACHE_PATH = \"valid/labels.cache\"  # Update if needed\n",
    "if os.path.exists(CACHE_PATH):\n",
    "    print(f\"ðŸ§¹ Removing corrupted cache: {CACHE_PATH}\")\n",
    "    os.remove(CACHE_PATH)\n",
    "\n",
    "# ------------------------\n",
    "# ðŸš€ Step 2: Load model\n",
    "# ------------------------\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# ------------------------\n",
    "# ðŸ§ª Step 3: Run evaluation\n",
    "# ------------------------\n",
    "results = model.val(data=\"data_kaggle.yaml\")  # Update this if needed\n",
    "\n",
    "# ------------------------\n",
    "# ðŸ“¸ Step 4: Let user know where plots were saved\n",
    "# ------------------------\n",
    "print(f\"\\nðŸ“‚ Evaluation plots have been auto-saved to: {results.save_dir}\")\n",
    "print(\"ðŸ–¼ï¸ Plots include: PR curve, F1 curve, confusion matrix, label distribution\")\n",
    "\n",
    "# ------------------------\n",
    "# ðŸ§¾ Step 5: Print metrics\n",
    "# ------------------------\n",
    "metrics = results.box\n",
    "print(\"\\nðŸ“Š Model Evaluation Summary:\")\n",
    "print(f\"Precision:     {metrics.precision.mean():.4f}\")\n",
    "print(f\"Recall:        {metrics.recall.mean():.4f}\")\n",
    "print(f\"mAP@0.5:       {metrics.map50.mean():.4f}\")\n",
    "print(f\"mAP@0.5:0.95:  {metrics.map.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbcabd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.116 ðŸš€ Python-3.12.5 torch-2.2.2 CPU (Intel Core(TM) i7-8750H 2.20GHz)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.0 ms, read: 172.5Â±25.9 MB/s, size: 80.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/Dhruv/mlcasee/valid/labels.cache... 500 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [01:26<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       8253      0.031      0.334     0.0215    0.00909\n",
      "                person        495       5100     0.0392      0.313     0.0266     0.0109\n",
      "               bicycle        500       2372     0.0422     0.0489     0.0223    0.00814\n",
      "                   car        500        781     0.0116      0.639     0.0157    0.00829\n",
      "Speed: 4.1ms preprocess, 148.7ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "Saving /Users/Dhruv/runs/detect/val7/predictions.json...\n",
      "Results saved to \u001b[1m/Users/Dhruv/runs/detect/val7\u001b[0m\n",
      "\n",
      "ðŸ“Š Model Evaluation Summary:\n",
      "mAP50: 0.0215\n",
      "mAP50-95: 0.0091\n",
      "Precision: 0.0310\n",
      "Recall: 0.3336\n",
      "\n",
      "Per-class metrics:\n",
      "person: mAP50=0.0266, mAP50-95=0.0109\n",
      "bicycle: mAP50=0.0223, mAP50-95=0.0081\n",
      "car: mAP50=0.0157, mAP50-95=0.0083\n",
      "Could not create manual confusion matrix: path/to/val/images does not exist\n",
      "\n",
      "ðŸ” Available result attributes:\n",
      "['ap_class_index', 'box', 'class_result', 'confusion_matrix', 'curves', 'curves_results', 'fitness', 'keys', 'maps', 'mean_results', 'names', 'plot', 'process', 'results_dict', 'save_dir', 'speed', 'task']\n",
      "\n",
      "ðŸ“¦ Box metrics attributes:\n",
      "['all_ap', 'ap', 'ap50', 'ap_class_index', 'class_result', 'curves', 'curves_results', 'f1', 'f1_curve', 'fitness', 'map', 'map50', 'map75', 'maps', 'mean_results', 'mp', 'mr', 'nc', 'p', 'p_curve', 'prec_values', 'px', 'r', 'r_curve', 'update']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Summary Metrics:\n",
      "MP: 0.0310\n",
      "MR: 0.3336\n",
      "MAP50: 0.0215\n",
      "MAP: 0.0091\n"
     ]
    }
   ],
   "source": [
    "# %pip install --force-reinstall scikit-learn\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# -------------------------\n",
    "# 1. Load the fine-tuned model\n",
    "# -------------------------\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# -------------------------\n",
    "# 2. Evaluate the model\n",
    "# Replace with your YAML path if needed: data='path/to/data.yaml'\n",
    "results = model.val(data=\"data_kaggle.yaml\", save_json=True, plots=True)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Access metrics from the results object\n",
    "# -------------------------\n",
    "print(\"\\nðŸ“Š Model Evaluation Summary:\")\n",
    "print(f\"mAP50: {results.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {results.box.map:.4f}\")\n",
    "print(f\"Precision: {results.box.mp:.4f}\")\n",
    "print(f\"Recall: {results.box.mr:.4f}\")\n",
    "\n",
    "# Print per-class metrics if available\n",
    "if hasattr(results.box, 'ap_class_index') and results.box.ap_class_index is not None:\n",
    "    print(\"\\nPer-class metrics:\")\n",
    "    for i, class_idx in enumerate(results.box.ap_class_index):\n",
    "        class_name = results.names[class_idx]\n",
    "        print(f\"{class_name}: mAP50={results.box.ap50[i]:.4f}, mAP50-95={results.box.ap[i]:.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# 4. Plot results from saved files\n",
    "# -------------------------\n",
    "# The model.val() with plots=True automatically saves plots to runs/detect/val/\n",
    "# Let's find the latest validation run directory\n",
    "runs_dir = \"runs/detect\"\n",
    "if os.path.exists(runs_dir):\n",
    "    val_dirs = [d for d in os.listdir(runs_dir) if d.startswith('val')]\n",
    "    if val_dirs:\n",
    "        # Get the most recent validation directory\n",
    "        latest_val = max(val_dirs, key=lambda x: os.path.getctime(os.path.join(runs_dir, x)))\n",
    "        val_path = os.path.join(runs_dir, latest_val)\n",
    "        print(f\"\\nðŸ“ˆ Plots saved to: {val_path}\")\n",
    "        \n",
    "        # List available plot files\n",
    "        plot_files = [f for f in os.listdir(val_path) if f.endswith('.png')]\n",
    "        if plot_files:\n",
    "            print(\"Available plots:\")\n",
    "            for plot_file in plot_files:\n",
    "                print(f\"  - {plot_file}\")\n",
    "\n",
    "# -------------------------\n",
    "# 5. Alternative: Manual confusion matrix using predictions\n",
    "# -------------------------\n",
    "def create_confusion_matrix_from_predictions():\n",
    "    \"\"\"\n",
    "    Create confusion matrix by running predictions on validation set\n",
    "    \"\"\"\n",
    "    # This is a more manual approach if you need the raw confusion matrix data\n",
    "    try:\n",
    "        # Get validation dataset path from yaml (you may need to adjust this)\n",
    "        val_results = model.predict(source=\"path/to/val/images\", save=False, verbose=False)\n",
    "        \n",
    "        # Note: Creating a proper confusion matrix requires ground truth labels\n",
    "        # which would need to be loaded from your dataset\n",
    "        print(\"To create a detailed confusion matrix, you would need to:\")\n",
    "        print(\"1. Load ground truth labels from your validation set\")\n",
    "        print(\"2. Compare with model predictions\")\n",
    "        print(\"3. Use sklearn.metrics.confusion_matrix\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not create manual confusion matrix: {e}\")\n",
    "\n",
    "create_confusion_matrix_from_predictions()\n",
    "\n",
    "# -------------------------\n",
    "# 6. Display built-in YOLO plots if they exist\n",
    "# -------------------------\n",
    "def display_yolo_plots(val_path):\n",
    "    \"\"\"Display the automatically generated YOLO plots\"\"\"\n",
    "    if not os.path.exists(val_path):\n",
    "        print(\"Validation plots directory not found.\")\n",
    "        return\n",
    "    \n",
    "    # Common YOLO plot files\n",
    "    plot_files = {\n",
    "        'confusion_matrix.png': 'Confusion Matrix',\n",
    "        'F1_curve.png': 'F1 Score Curve',\n",
    "        'P_curve.png': 'Precision Curve',\n",
    "        'R_curve.png': 'Recall Curve',\n",
    "        'PR_curve.png': 'Precision-Recall Curve'\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    plot_count = 0\n",
    "    for filename, title in plot_files.items():\n",
    "        filepath = os.path.join(val_path, filename)\n",
    "        if os.path.exists(filepath):\n",
    "            img = plt.imread(filepath)\n",
    "            axes[plot_count].imshow(img)\n",
    "            axes[plot_count].set_title(title)\n",
    "            axes[plot_count].axis('off')\n",
    "            plot_count += 1\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(plot_count, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Try to display the plots\n",
    "if 'val_path' in locals():\n",
    "    display_yolo_plots(val_path)\n",
    "\n",
    "# -------------------------\n",
    "# 7. Alternative: Use model.metrics if available\n",
    "# -------------------------\n",
    "print(\"\\nðŸ” Available result attributes:\")\n",
    "print([attr for attr in dir(results) if not attr.startswith('_')])\n",
    "\n",
    "if hasattr(results, 'box'):\n",
    "    print(\"\\nðŸ“¦ Box metrics attributes:\")\n",
    "    print([attr for attr in dir(results.box) if not attr.startswith('_')])\n",
    "\n",
    "# -------------------------\n",
    "# 8. Custom plotting function using available metrics\n",
    "# -------------------------\n",
    "def plot_available_metrics(results):\n",
    "    \"\"\"Plot whatever metrics are available in the results object\"\"\"\n",
    "    \n",
    "    if hasattr(results.box, 'ap') and results.box.ap is not None:\n",
    "        # Plot mAP per class\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        class_names = [results.names[i] for i in range(len(results.names))]\n",
    "        ap_values = results.box.ap if len(results.box.ap) == len(class_names) else [results.box.map]\n",
    "        \n",
    "        plt.bar(class_names, ap_values)\n",
    "        plt.xlabel('Classes')\n",
    "        plt.ylabel('Average Precision (AP)')\n",
    "        plt.title('Average Precision per Class')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Print summary metrics\n",
    "    metrics_to_show = ['mp', 'mr', 'map50', 'map']\n",
    "    print(\"\\nðŸ“Š Summary Metrics:\")\n",
    "    for metric in metrics_to_show:\n",
    "        if hasattr(results.box, metric):\n",
    "            value = getattr(results.box, metric)\n",
    "            print(f\"{metric.upper()}: {value:.4f}\")\n",
    "\n",
    "plot_available_metrics(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42f738f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.116 ðŸš€ Python-3.12.5 torch-2.2.2 CPU (Intel Core(TM) i7-8750H 2.20GHz)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.2Â±0.1 ms, read: 143.1Â±38.4 MB/s, size: 75.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/Dhruv/mlcasee/valid/labels.cache... 500 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [01:33<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       8253      0.031      0.334     0.0215    0.00909\n",
      "                person        495       5100     0.0392      0.313     0.0266     0.0109\n",
      "               bicycle        500       2372     0.0422     0.0489     0.0223    0.00814\n",
      "                   car        500        781     0.0116      0.639     0.0157    0.00829\n",
      "Speed: 4.2ms preprocess, 160.6ms inference, 0.0ms loss, 5.6ms postprocess per image\n",
      "Saving /Users/Dhruv/runs/detect/val9/predictions.json...\n",
      "Results saved to \u001b[1m/Users/Dhruv/runs/detect/val9\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "'y1' is not 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     71\u001b[39m     plt.tight_layout()\n\u001b[32m     72\u001b[39m     plt.show()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[43mplot_f1_vs_conf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# 5. Confusion Matrix\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_confusion_matrix\u001b[39m(results):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mplot_f1_vs_conf\u001b[39m\u001b[34m(results)\u001b[39m\n\u001b[32m     60\u001b[39m         \u001b[38;5;66;03m# Plot overall F1 curve\u001b[39;00m\n\u001b[32m     61\u001b[39m         plt.plot(conf_thresholds, f1_curve, color=\u001b[33m'\u001b[39m\u001b[33mpurple\u001b[39m\u001b[33m'\u001b[39m, linewidth=\u001b[32m2\u001b[39m, label=\u001b[33m'\u001b[39m\u001b[33mF1 Score\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill_between\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf_thresholds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf1_curve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpurple\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mConfidence Threshold\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m12\u001b[39m)\n\u001b[32m     65\u001b[39m plt.ylabel(\u001b[33m'\u001b[39m\u001b[33mF1 Score\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m12\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/matplotlib/pyplot.py:3340\u001b[39m, in \u001b[36mfill_between\u001b[39m\u001b[34m(x, y1, y2, where, interpolate, step, data, **kwargs)\u001b[39m\n\u001b[32m   3328\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes.fill_between)\n\u001b[32m   3329\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfill_between\u001b[39m(\n\u001b[32m   3330\u001b[39m     x: ArrayLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3338\u001b[39m     **kwargs,\n\u001b[32m   3339\u001b[39m ) -> FillBetweenPolyCollection:\n\u001b[32m-> \u001b[39m\u001b[32m3340\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill_between\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3341\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3342\u001b[39m \u001b[43m        \u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3343\u001b[39m \u001b[43m        \u001b[49m\u001b[43my2\u001b[49m\u001b[43m=\u001b[49m\u001b[43my2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3345\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterpolate\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpolate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3346\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3347\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3348\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3349\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/matplotlib/__init__.py:1521\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1518\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1520\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1521\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1526\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1527\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1528\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5716\u001b[39m, in \u001b[36mAxes.fill_between\u001b[39m\u001b[34m(self, x, y1, y2, where, interpolate, step, **kwargs)\u001b[39m\n\u001b[32m   5714\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfill_between\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y1, y2=\u001b[32m0\u001b[39m, where=\u001b[38;5;28;01mNone\u001b[39;00m, interpolate=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   5715\u001b[39m                  step=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m5716\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fill_between_x_or_y\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5717\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5718\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolate\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpolate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5701\u001b[39m, in \u001b[36mAxes._fill_between_x_or_y\u001b[39m\u001b[34m(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs)\u001b[39m\n\u001b[32m   5696\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mfacecolor\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._get_patches_for_fill.get_next_color()\n\u001b[32m   5698\u001b[39m ind, dep1, dep2 = \u001b[38;5;28mself\u001b[39m._fill_between_process_units(\n\u001b[32m   5699\u001b[39m     ind_dir, dep_dir, ind, dep1, dep2, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m5701\u001b[39m collection = \u001b[43mmcoll\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFillBetweenPolyCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5702\u001b[39m \u001b[43m    \u001b[49m\u001b[43mind_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdep1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdep2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolate\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpolate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5705\u001b[39m \u001b[38;5;28mself\u001b[39m.add_collection(collection)\n\u001b[32m   5706\u001b[39m \u001b[38;5;28mself\u001b[39m._request_autoscale_view()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/matplotlib/collections.py:1340\u001b[39m, in \u001b[36mFillBetweenPolyCollection.__init__\u001b[39m\u001b[34m(self, t_direction, t, f1, f2, where, interpolate, step, **kwargs)\u001b[39m\n\u001b[32m   1338\u001b[39m \u001b[38;5;28mself\u001b[39m._interpolate = interpolate\n\u001b[32m   1339\u001b[39m \u001b[38;5;28mself\u001b[39m._step = step\n\u001b[32m-> \u001b[39m\u001b[32m1340\u001b[39m verts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_verts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1341\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(verts, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/matplotlib/collections.py:1404\u001b[39m, in \u001b[36mFillBetweenPolyCollection._make_verts\u001b[39m\u001b[34m(self, t, f1, f2, where)\u001b[39m\n\u001b[32m   1400\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_verts\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, f1, f2, where):\n\u001b[32m   1401\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1402\u001b[39m \u001b[33;03m    Make verts that can be forwarded to `.PolyCollection`.\u001b[39;00m\n\u001b[32m   1403\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1404\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mt_direction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_f_direction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1406\u001b[39m     where = \u001b[38;5;28mself\u001b[39m._get_data_mask(t, f1, f2, where)\n\u001b[32m   1407\u001b[39m     t, f1, f2 = np.broadcast_arrays(np.atleast_1d(t), f1, f2, subok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/matplotlib/collections.py:1442\u001b[39m, in \u001b[36mFillBetweenPolyCollection._validate_shapes\u001b[39m\u001b[34m(t_dir, f_dir, t, f1, f2)\u001b[39m\n\u001b[32m   1440\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, array \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(names, [t, f1, f2]):\n\u001b[32m   1441\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m array.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1442\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m is not 1-dimensional\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m t.size > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.size > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m t.size != array.size:\n\u001b[32m   1444\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m has size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, but \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m has an unequal size of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   1445\u001b[39m             t_dir, t.size, name, array.size)\n",
      "\u001b[31mValueError\u001b[39m: 'y1' is not 1-dimensional"
     ]
    }
   ],
   "source": [
    "# %pip install --force-reinstall scikit-learn\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# -------------------------\n",
    "# 1. Load the fine-tuned model\n",
    "# -------------------------\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# -------------------------\n",
    "# 2. Evaluate the model\n",
    "# Replace with your YAML path if needed: data='path/to/data.yaml'\n",
    "results = model.val(data=\"data_kaggle.yaml\", save_json=True, plots=True)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Precision-Recall Curve\n",
    "# -------------------------\n",
    "def plot_pr_curve(results):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Access PR curves from results\n",
    "    if hasattr(results.box, 'p_curve') and hasattr(results.box, 'r_curve'):\n",
    "        p_curve = results.box.p_curve\n",
    "        r_curve = results.box.r_curve\n",
    "        \n",
    "        # Plot for each class\n",
    "        for i, class_name in results.names.items():\n",
    "            if i < len(p_curve) and i < len(r_curve):\n",
    "                plt.plot(r_curve[i], p_curve[i], label=f'{class_name}', linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Recall', fontsize=12)\n",
    "    plt.ylabel('Precision', fontsize=12)\n",
    "    plt.title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_pr_curve(results)\n",
    "\n",
    "# -------------------------\n",
    "# 4. F1 Score vs Confidence Threshold\n",
    "# -------------------------\n",
    "def plot_f1_vs_conf(results):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    if hasattr(results.box, 'f1_curve'):\n",
    "        f1_curve = results.box.f1_curve\n",
    "        \n",
    "        # F1 curve is typically [confidence_thresholds, f1_scores]\n",
    "        if f1_curve is not None and len(f1_curve) > 0:\n",
    "            # Create confidence thresholds (typically from 0 to 1)\n",
    "            conf_thresholds = np.linspace(0, 1, len(f1_curve))\n",
    "            \n",
    "            # Plot overall F1 curve\n",
    "            plt.plot(conf_thresholds, f1_curve, color='purple', linewidth=2, label='F1 Score')\n",
    "            plt.fill_between(conf_thresholds, f1_curve, alpha=0.2, color='purple')\n",
    "    \n",
    "    plt.xlabel('Confidence Threshold', fontsize=12)\n",
    "    plt.ylabel('F1 Score', fontsize=12)\n",
    "    plt.title('F1 Score vs Confidence Threshold', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_f1_vs_conf(results)\n",
    "\n",
    "# -------------------------\n",
    "# 5. Confusion Matrix\n",
    "# -------------------------\n",
    "def plot_confusion_matrix(results):\n",
    "    if hasattr(results, 'confusion_matrix') and results.confusion_matrix is not None:\n",
    "        matrix = results.confusion_matrix.matrix\n",
    "        class_names = list(results.names.values())\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Create confusion matrix display\n",
    "        disp = ConfusionMatrixDisplay(\n",
    "            confusion_matrix=matrix, \n",
    "            display_labels=class_names\n",
    "        )\n",
    "        \n",
    "        disp.plot(cmap='Blues', values_format='d', ax=plt.gca())\n",
    "        plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Confusion matrix not available in results\")\n",
    "\n",
    "plot_confusion_matrix(results)\n",
    "\n",
    "# -------------------------\n",
    "# 6. Additional Visualizations\n",
    "# -------------------------\n",
    "def plot_precision_recall_curves_detailed(results):\n",
    "    \"\"\"Plot detailed precision and recall curves\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Precision curve\n",
    "    if hasattr(results.box, 'p_curve'):\n",
    "        ax1.set_title('Precision vs Confidence', fontsize=14, fontweight='bold')\n",
    "        for i, class_name in results.names.items():\n",
    "            if i < len(results.box.p_curve):\n",
    "                conf_thresholds = np.linspace(0, 1, len(results.box.p_curve[i]))\n",
    "                ax1.plot(conf_thresholds, results.box.p_curve[i], label=f'{class_name}', linewidth=2)\n",
    "        ax1.set_xlabel('Confidence')\n",
    "        ax1.set_ylabel('Precision')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Recall curve\n",
    "    if hasattr(results.box, 'r_curve'):\n",
    "        ax2.set_title('Recall vs Confidence', fontsize=14, fontweight='bold')\n",
    "        for i, class_name in results.names.items():\n",
    "            if i < len(results.box.r_curve):\n",
    "                conf_thresholds = np.linspace(0, 1, len(results.box.r_curve[i]))\n",
    "                ax2.plot(conf_thresholds, results.box.r_curve[i], label=f'{class_name}', linewidth=2)\n",
    "        ax2.set_xlabel('Confidence')\n",
    "        ax2.set_ylabel('Recall')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_precision_recall_curves_detailed(results)\n",
    "\n",
    "# -------------------------\n",
    "# 7. mAP and Summary Metrics with Visualization\n",
    "# -------------------------\n",
    "def plot_class_performance(results):\n",
    "    \"\"\"Plot per-class performance metrics\"\"\"\n",
    "    class_names = list(results.names.values())\n",
    "    \n",
    "    # Get per-class metrics\n",
    "    if hasattr(results.box, 'ap50') and len(results.box.ap50) == len(class_names):\n",
    "        ap50_values = results.box.ap50\n",
    "        ap_values = results.box.ap if hasattr(results.box, 'ap') else [0] * len(class_names)\n",
    "        \n",
    "        # Create subplot\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # mAP50 per class\n",
    "        bars1 = ax1.bar(class_names, ap50_values, color='skyblue', alpha=0.7, edgecolor='navy')\n",
    "        ax1.set_title('mAP@0.5 per Class', fontsize=14, fontweight='bold')\n",
    "        ax1.set_ylabel('mAP@0.5')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars1, ap50_values):\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "                    f'{value:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # mAP50-95 per class\n",
    "        bars2 = ax2.bar(class_names, ap_values, color='lightcoral', alpha=0.7, edgecolor='darkred')\n",
    "        ax2.set_title('mAP@0.5:0.95 per Class', fontsize=14, fontweight='bold')\n",
    "        ax2.set_ylabel('mAP@0.5:0.95')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars2, ap_values):\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.0005,\n",
    "                    f'{value:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_class_performance(results)\n",
    "\n",
    "# -------------------------\n",
    "# 8. Print comprehensive metrics summary\n",
    "# -------------------------\n",
    "print(\"\\nðŸ“Š Model Evaluation Summary:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Overall Performance:\")\n",
    "print(f\"  mAP@0.5: {results.box.map50:.4f}\")\n",
    "print(f\"  mAP@0.5:0.95: {results.box.map:.4f}\")\n",
    "print(f\"  Precision: {results.box.mp:.4f}\")\n",
    "print(f\"  Recall: {results.box.mr:.4f}\")\n",
    "\n",
    "# Print per-class metrics if available\n",
    "if hasattr(results.box, 'ap_class_index') and results.box.ap_class_index is not None:\n",
    "    print(f\"\\nPer-class Performance:\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, class_idx in enumerate(results.box.ap_class_index):\n",
    "        class_name = results.names[class_idx]\n",
    "        ap50 = results.box.ap50[i] if i < len(results.box.ap50) else 0\n",
    "        ap = results.box.ap[i] if i < len(results.box.ap) else 0\n",
    "        print(f\"  {class_name:10s}: mAP@0.5={ap50:.4f}, mAP@0.5:0.95={ap:.4f}\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0705923c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.116 ðŸš€ Python-3.12.5 torch-2.2.2 CPU (Intel Core(TM) i7-8750H 2.20GHz)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     11\u001b[39m model = YOLO(\u001b[33m\"\u001b[39m\u001b[33myolo11n.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 2. Evaluate the model\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Replace with your YAML path if needed: data='path/to/data.yaml'\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata_kaggle.yaml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_json\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplots\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# 3. Precision-Recall Curve\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_pr_curve\u001b[39m(results):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/engine/model.py:627\u001b[39m, in \u001b[36mModel.val\u001b[39m\u001b[34m(self, validator, **kwargs)\u001b[39m\n\u001b[32m    624\u001b[39m args = {**\u001b[38;5;28mself\u001b[39m.overrides, **custom, **kwargs, \u001b[33m\"\u001b[39m\u001b[33mmode\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[32m    626\u001b[39m validator = (validator \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._smart_load(\u001b[33m\"\u001b[39m\u001b[33mvalidator\u001b[39m\u001b[33m\"\u001b[39m))(args=args, _callbacks=\u001b[38;5;28mself\u001b[39m.callbacks)\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[38;5;28mself\u001b[39m.metrics = validator.metrics\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m validator.metrics\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/engine/validator.py:179\u001b[39m, in \u001b[36mBaseValidator.__call__\u001b[39m\u001b[34m(self, trainer, model)\u001b[39m\n\u001b[32m    176\u001b[39m     LOGGER.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSetting batch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.args.batch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m input of shape (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.args.batch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, 3, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgsz\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.args.data).split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33myaml\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33myml\u001b[39m\u001b[33m\"\u001b[39m}:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.task == \u001b[33m\"\u001b[39m\u001b[33mclassify\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = check_cls_dataset(\u001b[38;5;28mself\u001b[39m.args.data, split=\u001b[38;5;28mself\u001b[39m.args.split)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/data/utils.py:468\u001b[39m, in \u001b[36mcheck_det_dataset\u001b[39m\u001b[34m(dataset, autodownload)\u001b[39m\n\u001b[32m    466\u001b[39m         s = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msuccess âœ… \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolorstr(\u001b[33m'\u001b[39m\u001b[33mbold\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39mDATASETS_DIR)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m} \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfailure \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m âŒ\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    467\u001b[39m         LOGGER.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset download \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m \u001b[43mcheck_font\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mArial.ttf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnames\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mArial.Unicode.ttf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# download fonts\u001b[39;00m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/utils/__init__.py:468\u001b[39m, in \u001b[36mThreadingLocked.__call__.<locals>.decorated\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    466\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Applies thread-safety to the decorated function or method.\"\"\"\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lock:\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/ultralytics/utils/checks.py:316\u001b[39m, in \u001b[36mcheck_font\u001b[39m\u001b[34m(font)\u001b[39m\n\u001b[32m    313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n\u001b[32m    315\u001b[39m \u001b[38;5;66;03m# Check system fonts\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m matches = [s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfont_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfindSystemFonts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m font \u001b[38;5;129;01min\u001b[39;00m s]\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(matches):\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m matches[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/matplotlib/font_manager.py:293\u001b[39m, in \u001b[36mfindSystemFonts\u001b[39m\u001b[34m(fontpaths, fontext)\u001b[39m\n\u001b[32m    291\u001b[39m installed_fonts = _get_fontconfig_fonts()\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys.platform == \u001b[33m'\u001b[39m\u001b[33mdarwin\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     installed_fonts += \u001b[43m_get_macos_fonts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m     fontpaths = [*X11FontDirectories, *OSXFontDirectories]\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlcasee/.venv/lib/python3.12/site-packages/matplotlib/font_manager.py:269\u001b[39m, in \u001b[36m_get_macos_fonts\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Cache and list the font paths known to ``system_profiler SPFontsDataType``.\"\"\"\u001b[39;00m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    268\u001b[39m     d, = plistlib.loads(\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m         \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem_profiler\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-xml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSPFontsDataType\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, subprocess.CalledProcessError, plistlib.InvalidFileException):\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:466\u001b[39m, in \u001b[36mcheck_output\u001b[39m\u001b[34m(timeout, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    463\u001b[39m         empty = \u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    464\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33minput\u001b[39m\u001b[33m'\u001b[39m] = empty\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m           \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.stdout\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:550\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    552\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:1196\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1194\u001b[39m     \u001b[38;5;28mself\u001b[39m._stdin_write(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m   1195\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stdout:\n\u001b[32m-> \u001b[39m\u001b[32m1196\u001b[39m     stdout = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1197\u001b[39m     \u001b[38;5;28mself\u001b[39m.stdout.close()\n\u001b[32m   1198\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stderr:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# %pip install --force-reinstall scikit-learn\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# -------------------------\n",
    "# 1. Load the fine-tuned model\n",
    "# -------------------------\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# -------------------------\n",
    "# 2. Evaluate the model\n",
    "# Replace with your YAML path if needed: data='path/to/data.yaml'\n",
    "results = model.val(data=\"data_kaggle.yaml\", save_json=True, plots=True)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Precision-Recall Curve\n",
    "# -------------------------\n",
    "def plot_pr_curve(results):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Access PR curves from results\n",
    "    if hasattr(results.box, 'p_curve') and hasattr(results.box, 'r_curve'):\n",
    "        p_curve = results.box.p_curve\n",
    "        r_curve = results.box.r_curve\n",
    "        \n",
    "        # Plot for each class\n",
    "        for i, class_name in results.names.items():\n",
    "            if i < len(p_curve) and i < len(r_curve):\n",
    "                plt.plot(r_curve[i], p_curve[i], label=f'{class_name}', linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Recall', fontsize=12)\n",
    "    plt.ylabel('Precision', fontsize=12)\n",
    "    plt.title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_pr_curve(results)\n",
    "\n",
    "# -------------------------\n",
    "# 4. F1 Score vs Confidence Threshold\n",
    "# -------------------------\n",
    "def plot_f1_vs_conf(results):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    if hasattr(results.box, 'f1_curve'):\n",
    "        f1_curve = results.box.f1_curve\n",
    "        \n",
    "        # F1 curve is typically [confidence_thresholds, f1_scores]\n",
    "        if f1_curve is not None and len(f1_curve) > 0:\n",
    "            # Create confidence thresholds (typically from 0 to 1)\n",
    "            conf_thresholds = np.linspace(0, 1, len(f1_curve))\n",
    "            \n",
    "            # Plot overall F1 curve\n",
    "            plt.plot(conf_thresholds, f1_curve, color='purple', linewidth=2, label='F1 Score')\n",
    "            plt.fill_between(conf_thresholds, f1_curve, alpha=0.2, color='purple')\n",
    "    \n",
    "    plt.xlabel('Confidence Threshold', fontsize=12)\n",
    "    plt.ylabel('F1 Score', fontsize=12)\n",
    "    plt.title('F1 Score vs Confidence Threshold', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_f1_vs_conf(results)\n",
    "\n",
    "# -------------------------\n",
    "# 5. Confusion Matrix\n",
    "# -------------------------\n",
    "def plot_confusion_matrix(results):\n",
    "    if hasattr(results, 'confusion_matrix') and results.confusion_matrix is not None:\n",
    "        matrix = results.confusion_matrix.matrix\n",
    "        class_names = list(results.names.values())\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Create confusion matrix display\n",
    "        disp = ConfusionMatrixDisplay(\n",
    "            confusion_matrix=matrix, \n",
    "            display_labels=class_names\n",
    "        )\n",
    "        \n",
    "        disp.plot(cmap='Blues', values_format='d', ax=plt.gca())\n",
    "        plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Confusion matrix not available in results\")\n",
    "\n",
    "plot_confusion_matrix(results)\n",
    "\n",
    "# -------------------------\n",
    "# 6. Additional Visualizations\n",
    "# -------------------------\n",
    "def plot_precision_recall_curves_detailed(results):\n",
    "    \"\"\"Plot detailed precision and recall curves\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Precision curve\n",
    "    if hasattr(results.box, 'p_curve'):\n",
    "        ax1.set_title('Precision vs Confidence', fontsize=14, fontweight='bold')\n",
    "        for i, class_name in results.names.items():\n",
    "            if i < len(results.box.p_curve):\n",
    "                conf_thresholds = np.linspace(0, 1, len(results.box.p_curve[i]))\n",
    "                ax1.plot(conf_thresholds, results.box.p_curve[i], label=f'{class_name}', linewidth=2)\n",
    "        ax1.set_xlabel('Confidence')\n",
    "        ax1.set_ylabel('Precision')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Recall curve\n",
    "    if hasattr(results.box, 'r_curve'):\n",
    "        ax2.set_title('Recall vs Confidence', fontsize=14, fontweight='bold')\n",
    "        for i, class_name in results.names.items():\n",
    "            if i < len(results.box.r_curve):\n",
    "                conf_thresholds = np.linspace(0, 1, len(results.box.r_curve[i]))\n",
    "                ax2.plot(conf_thresholds, results.box.r_curve[i], label=f'{class_name}', linewidth=2)\n",
    "        ax2.set_xlabel('Confidence')\n",
    "        ax2.set_ylabel('Recall')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_precision_recall_curves_detailed(results)\n",
    "\n",
    "# -------------------------\n",
    "# 7. mAP and Summary Metrics with Visualization\n",
    "# -------------------------\n",
    "def plot_class_performance(results):\n",
    "    \"\"\"Plot per-class performance metrics\"\"\"\n",
    "    class_names = list(results.names.values())\n",
    "    \n",
    "    # Get per-class metrics\n",
    "    if hasattr(results.box, 'ap50') and len(results.box.ap50) == len(class_names):\n",
    "        ap50_values = results.box.ap50\n",
    "        ap_values = results.box.ap if hasattr(results.box, 'ap') else [0] * len(class_names)\n",
    "        \n",
    "        # Create subplot\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # mAP50 per class\n",
    "        bars1 = ax1.bar(class_names, ap50_values, color='skyblue', alpha=0.7, edgecolor='navy')\n",
    "        ax1.set_title('mAP@0.5 per Class', fontsize=14, fontweight='bold')\n",
    "        ax1.set_ylabel('mAP@0.5')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars1, ap50_values):\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "                    f'{value:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # mAP50-95 per class\n",
    "        bars2 = ax2.bar(class_names, ap_values, color='lightcoral', alpha=0.7, edgecolor='darkred')\n",
    "        ax2.set_title('mAP@0.5:0.95 per Class', fontsize=14, fontweight='bold')\n",
    "        ax2.set_ylabel('mAP@0.5:0.95')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars2, ap_values):\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.0005,\n",
    "                    f'{value:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_class_performance(results)\n",
    "\n",
    "# -------------------------\n",
    "# 8. Print comprehensive metrics summary\n",
    "# -------------------------\n",
    "print(\"\\nðŸ“Š Model Evaluation Summary:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Overall Performance:\")\n",
    "print(f\"  mAP@0.5: {results.box.map50:.4f}\")\n",
    "print(f\"  mAP@0.5:0.95: {results.box.map:.4f}\")\n",
    "print(f\"  Precision: {results.box.mp:.4f}\")\n",
    "print(f\"  Recall: {results.box.mr:.4f}\")\n",
    "\n",
    "# Print per-class metrics if available\n",
    "if hasattr(results.box, 'ap_class_index') and results.box.ap_class_index is not None:\n",
    "    print(f\"\\nPer-class Performance:\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, class_idx in enumerate(results.box.ap_class_index):\n",
    "        class_name = results.names[class_idx]\n",
    "        ap50 = results.box.ap50[i] if i < len(results.box.ap50) else 0\n",
    "        ap = results.box.ap[i] if i < len(results.box.ap) else 0\n",
    "        print(f\"  {class_name:10s}: mAP@0.5={ap50:.4f}, mAP@0.5:0.95={ap:.4f}\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d132b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
